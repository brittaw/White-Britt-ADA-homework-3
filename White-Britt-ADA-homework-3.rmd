---
title: "White-Britt-ADA-homework-3"
author: "BA White"
date: "5/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages and dataset
```{r}
library(tidyverse)
library(curl)
library(dplyr)
read <- curl("https://raw.githubusercontent.com/difiore/ADA-datasets/master/KamilarAndCooperData.csv")
data <- read.csv(read, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(data)
```

## Challenge 1
Aim: Fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean). 
Task: For both longevity~brain size and log(longevity)~log(brain size) complete the following:
```{r}
# Fit the regression model and, using {ggplot2}
lm <- lm(Brain_Size_Species_Mean ~ MaxLongevity_m, data)
summary(lm)

data <- data %>% 
  mutate(log_BMASSFM = (log(Body_mass_female_mean)),
  logMaxLongevity = (log(MaxLongevity_m)))

loglm <-lm(log_BMASSFM ~ logMaxLongevity, data)
summary(loglm)

# produce a scatterplot with the fitted line
(plotlm <- ggplot(lm, aes(Brain_Size_Species_Mean, MaxLongevity_m)) + geom_point() + geom_smooth(method="lm", se=FALSE))
(plotlog_lm <- ggplot(lm, aes(log(Brain_Size_Species_Mean), log(MaxLongevity_m))) + geom_point() + geom_smooth(method="lm", se=FALSE))
```

### Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses
```{r}
# Y (response variable) = β0 (intercept) + β1Xi (predictor variable)+ ϵi (random error variable)
nanodata<-na.omit(data)
bss<-nanodata$Brain_Size_Species_Mean
lgv<-nanodata$MaxLongevity_m
(pointestimate_slope <- cor(bss, lgv) * (sd(lgv) / sd(bss)))

# Since the slope is positive and almost one to one my interpretation is that brain size species means do predict/correlate to longevity. 
```

### Find a 90% CI for the slope (β1) parameter.
```{r}
alpha <- 0.10
# extract CIs from the model with
# using the results of lm()
(CI <- confint(lm, level = 1 - alpha))
(CIlog <- confint(loglm, level = 1 - alpha))
```

### Add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.
```{r}
library(broom)
y.hat <- predict(loglm, newdata = data.frame(logMaxLongevity = data$logMaxLongevity))
df <- data.frame(cbind(data$logMaxLongevity, data$log_BMASSFM, y.hat))
names(df) <- c("x", "y", "yhat")
df <- augment(loglm)

# confidence intervals
df <- df %>%
  mutate(
    c.lwr = .fitted - qt(1 - alpha / 2, nrow(df) - 2) * .se.fit,
    c.upr = .fitted + qt(1 - alpha / 2, nrow(df) - 2) * .se.fit
  )

# sd deviation of residuals
sd <- glance(loglm) %>% pull(sigma) 

#Now the predicted values 
df <- df %>%
# calculate a confidence interval for the predicted values
  mutate(
    se.prediction = sqrt(sd^2 + .se.fit^2),
    p.lwr = .fitted - qt(1 - alpha / 2, nrow(df) - 2) * se.prediction,
    p.upr = .fitted + qt(1 - alpha / 2, nrow(df) - 2) * se.prediction
  )
head(df)

g <- ggplot(data = data, aes(x = log_BMASSFM, y = logMaxLongevity))
g <- g + geom_point()
g <- g + geom_line(data = df,aes(x = log_BMASSFM, y = .fitted, color = "black"), na.rm = TRUE) 
g <- g + geom_line(data = df,aes(x = log_BMASSFM, y = c.lwr, color = "blue"), na.rm = TRUE) 
g <- g + geom_line(data = df, aes(x = log_BMASSFM, y = c.upr, color = "blue"), na.rm = TRUE) 
g <- g + geom_line(data = df,aes(x = log_BMASSFM, y = p.lwr, color = "red"), na.rm = TRUE) 
g <- g + geom_line(data = df,aes(x = log_BMASSFM, y = p.upr, color = "red"), na.rm = TRUE) 
g 

## legend plot
g2 <- ggplot(data = data, aes(x = log_BMASSFM, y = logMaxLongevity), alpha = 0.5) +
  geom_point(na.rm = TRUE) +
  # add regression line
  geom_line(
    data = df, aes(x = log_BMASSFM, y = .fitted), color = "black",
    lwd = 1
  ) +
  # add a ribbon layer
  geom_ribbon(
    data = df, aes(x = log_BMASSFM, ymin = c.lwr, ymax = c.upr, colour = "Confidence Interval"),
    # ... with transparency set to 0.2
    alpha = 0.2,
    # ... and fill color blue
    fill = "blue"
  ) +
  geom_ribbon(
    data = df, aes(x = log_BMASSFM, ymin = p.lwr, ymax = p.upr, colour = "Prediction Interval"),
    # ... with transparency set to 0.2
    alpha = 0.2,
    # ... and fill color red
    fill = "red"
  )
g2
```

### Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 750 gm
```{r}
(b750 <- 248.9523 + (1.2180 * 750))
```

### Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
To some degree, yes, because the R squared value denotes that almost 50% of the variation can be attributed to the predictor variable and the graph indicates a linear relationship. 
### Looking at your two models (i.e., untransformed versus log-log transformed), which do you think is better? Why?
Log-transformed model appears to reduce the skew in the magnitude of differences in brain size and longevity from the different species allowing for a one:one, linear model whereas the untransformed data does not show as clear of a correlation because the species brain size and longevity are on different orders of magnitude.  

## Challenge 2

### run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) 
```{r}
data <- data %>% 
  mutate(log_BMASSFM = log(Body_mass_female_mean),
  logHOMER = (log(HomeRange_km2)))

rangeLM <- lm(log_BMASSFM ~ logHOMER, data)
```

### report your β coeffiecients (slope and intercept).
```{r}
summary(rangeLM) 
```

### use bootstrapping to sample from the dataset 1000 times with replacement,
```{r}
library(infer)
set.seed(213)
bootsbewalkin <- data %>%
  # specify model
  specify(log_BMASSFM ~ logHOMER) %>%
  # generate bootstrap replicates
  generate(reps = 1000, type = "bootstrap") %>%
  # calculate the slope statistic
  calculate(stat = "slope")
# Histogram 
hist(bootsbewalkin$stat,
  main = "Histogram of Bootstrapped\nSlope Values",
  xlab = "Slope Coefficient"
)

bootsbewalkin <- data %>%
  # specify model
  specify(log_BMASSFM ~ logHOMER) %>%
  # generate bootstrap replicates
  generate(reps = 1000, type = "bootstrap") 
slope <- vector()
intercept <- vector()
for (i in 1:213) {
  Reps <- filter(bootsbewalkin, replicate == i)
  Reps_B <- lm(log_BMASSFM ~ logHOMER, data = Reps)
  slope[[i]] <- Reps_B$coefficients[[2]]
  intercept[[i]] <- Reps_B$coefficients[[1]]
}

# store data points for accesibilty 
Brain_Range_Boot <- tibble(slope = slope, intercept = intercept)
```

### Plot a histogram of these (bootstrapping) sampling distributions for  β0 and  β1
```{r}

# histogram for slope β1
hist(Brain_Range_Boot$slope,
  main = "Histogram of Slope Values",
  xlab = "Slope")

# histogram for intercept β0
hist(Brain_Range_Boot$intercept,
  main = "Histogram of Intercept Values",
  xlab = "Intercept")
```

### Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap.
```{r}
# first define alpha, CI boundaries, and critical values
alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(Brain_Range_Boot) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

# β1
Brain_Range_Boot_ErrorS <- Brain_Range_Boot %>% 
  summarize(
    estimate = mean(slope),
    std.error = sd(slope),
    lower = estimate - std.error * critical_value,
    upper = estimate + std.error * critical_value,
    boot.lower = quantile(slope, p_lower),
    boot.upper = quantile(slope, p_upper)
    )
Brain_Range_Boot_ErrorS

# β0
Brain_Range_Boot_ErrorI <- Brain_Range_Boot %>% 
  summarize(
    estimate = mean(intercept),
    std.error = sd(intercept),
    lower = estimate - std.error * critical_value,
    upper = estimate + std.error * critical_value,
    boot.lower = quantile(slope, p_lower),
    boot.upper = quantile(slope, p_upper)
    )
Brain_Range_Boot_ErrorI
```


### How do the SEs estimated from the bootstrap sampling distribution compare to those estimated mathematically as part of lm() function?
The intercept changed by Brain_Range_Boot_ErrorI std.error 0.08398028	for lm() 0.10199 
The slope changed by Brain_Range_Boot_ErrorS std.error 0.03976625 for lm() 0.04147

### How do you bootstrap CIs compare to those estimated mathematically as part of the lm() function?
```{r}
alpha = 0.05
# extract CIs from the model with
# using the results of lm()
(CI <- confint(rangeLM, level = 1 - alpha))
```
Brain_Range_Boot_ErrorI Low 08.322983	& high	8.654079
Brain_Range_Boot_ErrorS Low 0.4299398	& high 0.5867199
The bootstrpped values and original lm() CI values are very similar with the original being narrower but they are very close. 

## Challenge 3
### Write your own function, called boot_lm()
```{r}
boot_lm <- function(d, model, conf.level=0.95, reps=1000){
  
# 1. Add data to d and log values  
 d <- d %>% 
   mutate(log_HomeRange = log(HomeRange_km2),
      log_BMASSFM = log(Body_mass_female_mean),
      log_DayLength = log(DayLength_km),
      log_MGS = log(MeanGroupSize))
 
# 2. What is the structure of 'model'
model <- as.formula(model)
fit <- lm(model, data = d)

# 3. bootstrappin'
bootsbewalkin <- d %>%
# generate bootstrap replicates
generate(reps = reps, type = "bootstrap") 
slope <- vector()
intercept <- vector()

# now rep function
for (i in 1:213) {
  Range_Boot <- filter(bootsbewalkin, replicate == i)
  Range_Bootlm <- lm(model, Range_Boot)
  slope[[i]] <- Range_Bootlm$coefficients[[2]]
  intercept[[i]] <- Range_Bootlm$coefficients[[1]]
}

# 4. store vectors for accesibilty 
Range_Boot <- tibble(slope = slope, intercept = intercept)

# 5. define alpha, CI boundaries, and critical values
alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(Range_Boot) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

# 5a. Slope β1
Range_Bootlm_ErrorS <- Range_Boot %>% 
  summarize(
    estimate = mean(slope),
    std.error = sd(slope),
    lower = estimate - std.error * critical_value,
    upper = estimate + std.error * critical_value,
    boot.lower = quantile(slope, p_lower),
    boot.upper = quantile(slope, p_upper)
    )
Range_Bootlm_ErrorS

# 5b. Intercept β0
Range_Bootlm_ErrorI <- Range_Boot %>% 
  summarize(
    estimate = mean(intercept),
    std.error = sd(intercept),
    lower = estimate - std.error * critical_value,
    upper = estimate + std.error * critical_value,
    boot.lower = quantile(slope, p_lower),
    boot.upper = quantile(slope, p_upper)
    )
Range_Bootlm_ErrorI

# combined 
C <-rbind(Range_Bootlm_ErrorS,Range_Bootlm_ErrorI)
C
}
```

### log(HomeRange_km2) ~ log(Body_mass_female_mean)
```{r}
boot_lm(d = data, model = "log_HomeRange ~ log_BMASSFM")
```

### log(DayLength_km) ~ log(Body_mass_female_mean)
```{r}
boot_lm(d = data, model = "log_DayLength ~ log_BMASSFM")
```

### log(HomeRange_km2) ~ log(Body_mass_female_mean) + MeanGroupSize
```{r}
boot_lm(d = data, model = "log_HomeRange ~ log_BMASSFM + log_MGS")
```


